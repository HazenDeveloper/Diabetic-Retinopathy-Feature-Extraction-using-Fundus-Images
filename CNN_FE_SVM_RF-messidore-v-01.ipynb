{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazenDeveloper/Diabetic-Retinopathy-Feature-Extraction-using-Fundus-Images/blob/master/CNN_FE_SVM_RF-messidore-v-01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUzMl-LWi0Pl",
        "outputId": "423982d4-5925-416f-a9e9-46196298b06e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bFbjIBEyceKU"
      },
      "outputs": [],
      "source": [
        "#!pip install imutils\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from sklearn.utils import shuffle\n",
        "from cv2 import imread\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4fuzmF_0Yvr",
        "outputId": "36411b5b-90de-450d-8e49-31b2d025fea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML-Datasets/Messidore\n"
          ]
        }
      ],
      "source": [
        "from os import listdir, walk\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "path = os.path.join(os.path.curdir,'/content/drive/MyDrive/ML-Datasets/Messidore')\n",
        "print(path)\n",
        "\n",
        "# print('testing', imagePaths[1].split(os.path.sep)[-2])\n",
        "\n",
        "# img = cv2.imread(imagePaths[2])\n",
        "# cv2_imshow(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3NJxQMYNe0cC",
        "outputId": "c1177c7d-4fb2-4753-d104-76253ae4205f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200 1200\n",
            "(1200, 256, 256, 3)\n",
            "(1200, 4)\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 4\n",
        "\n",
        "imagePaths = list(paths.list_images('/content/drive/MyDrive/ML-Datasets/train-test-val-nc'))\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/ML-Datasets/train-test-val-nc/train'\n",
        "test_data_dir = '/content/drive/MyDrive/ML-Datasets/train-test-val-nc/test'\n",
        "valid_data_dir = '/content/drive/MyDrive/ML-Datasets/train-test-val-nc/val'\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    image = load_img(imagePath, target_size=(width, height))\n",
        "    image = img_to_array(image)\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "print(len(data), len(labels))\n",
        "\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# le = LabelEncoder()\n",
        "# labels = le.fit_transform(labels)\n",
        "\n",
        "# ohe = OneHotEncoder()\n",
        "# labels = ohe.fit_transform(labels)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "#labels = to_categorical(labels)\n",
        "\n",
        "data, labels = shuffle(data, labels)\n",
        "\n",
        "print(data.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtJkMb8RgeP3",
        "outputId": "3d045127-ca29-4753-cc25-2c01228ff1c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (960, 256, 256, 3)\n",
            "Test images: (240, 256, 256, 3)\n",
            "Train label: (960, 4)\n",
            "Test label: (240, 4)\n"
          ]
        }
      ],
      "source": [
        "test_ratio = 0.2\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio)\n",
        "\n",
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_test.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train,test_size=test_ratio)"
      ],
      "metadata": {
        "id": "miBqYK_eylzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_valid.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_valid.shape)"
      ],
      "metadata": {
        "id": "SbJEYBdvy8P5",
        "outputId": "09b5eb54-a5b2-4e8b-b2e2-de4fef9ccb68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (768, 256, 256, 3)\n",
            "Test images: (192, 256, 256, 3)\n",
            "Train label: (768, 4)\n",
            "Test label: (192, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train.shape[0])"
      ],
      "metadata": {
        "id": "87BtFGvszq8F",
        "outputId": "396c456a-9caa-4310-8fff-b948bddc9cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = ImageDataGenerator(rescale = 1./255.0,\n",
        "                             rotation_range=15,\n",
        "                             zoom_range=0.2,\n",
        "                             shear_range=0.1)\n",
        "\n",
        "test_x = ImageDataGenerator(rescale = 1./255.0\n",
        "                             )\n",
        "valid_x = ImageDataGenerator(rescale = 1./255.0)\n",
        "\n",
        "trainData = train_x.flow(x_train, y_train)#,\n",
        "#                         #  batch_size=batch_size),\n",
        "#                         #  samples_per_epoch=X_train.shape[0],\n",
        "#                         #  nb_epoch=nb_epoch,\n",
        "#                         #  validation_data=(x_valid, y_valid),\n",
        "#                          class_mode='categorical')\n",
        "\n",
        "testData = test_x.flow(x_test, y_test)#,\n",
        "                    #  input_shape[:2],\n",
        "                    #  batch_size=x_test[0],\n",
        "                    #  class_mode='categorical')\n",
        "\n",
        "validData = test_x.flow(x_valid, y_valid)#,\n",
        "                    #  target_size=input_shape[:2],\n",
        "                    #  batch_size=x_test[0],\n",
        "                    #  class_mode='categorical')"
      ],
      "metadata": {
        "id": "s8_qhn6hpR-b",
        "outputId": "147e3f6f-3a04-4276-f5f3-4d6d4c3b75d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-87646433d517>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvalid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#                         #  batch_size=batch_size),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#                         #  samples_per_epoch=X_train.shape[0],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLE4RO53NyW0"
      },
      "outputs": [],
      "source": [
        "!pip install lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=False, custom_metric=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "\n",
        "# Preprocess the training data with data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,            # Normalize pixel values to [0, 1]\n",
        "                                   rotation_range=15,         # Randomly rotate images by 10 degrees\n",
        "                                  #  width_shift_range=0.1,   # Randomly shift images horizontally by 10% of the width\n",
        "                                   # height_shift_range=0.1,  # Randomly shift images vertically by 10% of the height\n",
        "                                   shear_range=0.1,         # Apply shear transformation with a shear angle of 10 degrees\n",
        "                                  #  zoom_range=0.2,          # Apply random zoom between 0.9x and 1.1x\n",
        "                                   horizontal_flip=True,    # Randomly flip images horizontally\n",
        "                                  #  vertical_flip=False      # Do not flip images vertically\n",
        "                                   )\n",
        "\n",
        "# Preprocess the validation and testing data (only rescale pixel values)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# Load and augment the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'   # Use categorical mode for multi-class classification\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the testing data\n",
        "test_generator = valid_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "VzEdrvd5ynTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3bf637-8c44-4c49-c196-d6d7c70d8541"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 838 images belonging to 4 classes.\n",
            "Found 238 images belonging to 4 classes.\n",
            "Found 124 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNet(width, heigth, depth, classes):\n",
        "\tmodel = Sequential()\n",
        "\tinput_shape = (heigth, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\tif keras.backend.image_data_format() == \"channel_first\":\n",
        "\t\tinput_shape = (depth, heigth, width)\n",
        "\t\tchanDim = 1\n",
        "\n",
        "\tmodel.add(Conv2D(16,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(128,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(BatchNormalization())\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(512, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization())\n",
        "\t# model.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "\treturn model\n"
      ],
      "metadata": {
        "id": "0YVgmPybsCro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNetv01(model):\n",
        "  chanDim = -1\n",
        "  width,height=256,256\n",
        "  depth = 3\n",
        "  input_shape = (height, width, depth)\n",
        "\n",
        "  if keras.backend.image_data_format() == \"channel_first\":\n",
        "    input_shape = (depth, heigth, width)\n",
        "    chanDim = 1\n",
        "\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(0.25))\n",
        "  # model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "OhMc3MUUrC6d"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 4\n",
        "depth = 3\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 50\n",
        "\n",
        "from keras.optimizers import Nadam, SGD\n",
        "model = Sequential()\n",
        "\n",
        "# cnn_model = MiniVGGNet(width, height, depth, classes)\n",
        "cnn_model = MiniVGGNetv01(model)\n",
        "\n",
        "opt = Nadam(learning_rate=INIT_LR)\n",
        "# opt = SGD(learning_rate=INIT_LR)\n",
        "# opt = Adam(learning_rate=INIT_LR)\n",
        "# opt = gradient_descent_legacy.SGD (learning_rate = INIT_LR)\n",
        "cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "5y1WoLKLtt3p",
        "outputId": "62d7c4d3-c304-4951-f5d9-da35c48d4c4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_32 (Conv2D)          (None, 256, 256, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 128, 128, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 128, 128, 16)      0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 128, 128, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 64, 64, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 64, 64, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 32, 32, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32, 32, 16)        0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1024)              16778240  \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 1024)             4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 4100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,805,524\n",
            "Trainable params: 16,803,412\n",
            "Non-trainable params: 2,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save the best model\n",
        "checkpoint_path = 'best_model.h5'\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "# Create the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    patience = 2,\n",
        "    monitor='val_accuracy',       # Metric to monitor (could also be 'val_accuracy', etc.)\n",
        "    save_best_only=True,      # Saves only the best model based on the monitored metric\n",
        "    # save_weights_only=False,  # Set to True to save only the model's weights, not the whole model\n",
        "    verbose=1                 # Verbosity level: 0 - silent, 1 - progress bar, 2 - one line per epoch.\n",
        ")\n",
        "# checkpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, mode='auto')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                              verbose=1,\n",
        "                              factor=0.2,\n",
        "                              patience=6,\n",
        "                              min_delta=0.005,\n",
        "                              cooldown=0,\n",
        "                              min_lr=0.001)\n",
        "\n",
        "my_callbacks = [model_checkpoint, reduce_lr]"
      ],
      "metadata": {
        "id": "oDaSr1KbyVcx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Uk-YNu0kgpnZ",
        "outputId": "9a876cf1-131c-447c-f11f-55fef4986ea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training head..\n",
            "Epoch 1/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.9268 - accuracy: 0.2969\n",
            "Epoch 1: val_accuracy improved from -inf to 0.19271, saving model to best_model.h5\n",
            "24/24 [==============================] - 10s 364ms/step - loss: 1.9268 - accuracy: 0.2969 - val_loss: 1.8918 - val_accuracy: 0.1927 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.7997 - accuracy: 0.3177\n",
            "Epoch 2: val_accuracy improved from 0.19271 to 0.22396, saving model to best_model.h5\n",
            "24/24 [==============================] - 5s 222ms/step - loss: 1.7997 - accuracy: 0.3177 - val_loss: 2.2128 - val_accuracy: 0.2240 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.6969 - accuracy: 0.3737\n",
            "Epoch 3: val_accuracy improved from 0.22396 to 0.40104, saving model to best_model.h5\n",
            "24/24 [==============================] - 5s 211ms/step - loss: 1.6969 - accuracy: 0.3737 - val_loss: 1.3569 - val_accuracy: 0.4010 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.5610 - accuracy: 0.3789\n",
            "Epoch 4: val_accuracy did not improve from 0.40104\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 1.5610 - accuracy: 0.3789 - val_loss: 1.3443 - val_accuracy: 0.3906 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.6127 - accuracy: 0.3451\n",
            "Epoch 5: val_accuracy improved from 0.40104 to 0.41667, saving model to best_model.h5\n",
            "24/24 [==============================] - 5s 234ms/step - loss: 1.6127 - accuracy: 0.3451 - val_loss: 1.2945 - val_accuracy: 0.4167 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.5545 - accuracy: 0.3581\n",
            "Epoch 6: val_accuracy improved from 0.41667 to 0.42708, saving model to best_model.h5\n",
            "24/24 [==============================] - 9s 380ms/step - loss: 1.5545 - accuracy: 0.3581 - val_loss: 1.3372 - val_accuracy: 0.4271 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.5810 - accuracy: 0.3776\n",
            "Epoch 7: val_accuracy did not improve from 0.42708\n",
            "24/24 [==============================] - 3s 127ms/step - loss: 1.5810 - accuracy: 0.3776 - val_loss: 1.3375 - val_accuracy: 0.4010 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.4605 - accuracy: 0.4010\n",
            "Epoch 8: val_accuracy did not improve from 0.42708\n",
            "24/24 [==============================] - 3s 126ms/step - loss: 1.4605 - accuracy: 0.4010 - val_loss: 1.3737 - val_accuracy: 0.4271 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.4101 - accuracy: 0.4049\n",
            "Epoch 9: val_accuracy improved from 0.42708 to 0.44271, saving model to best_model.h5\n",
            "24/24 [==============================] - 8s 340ms/step - loss: 1.4101 - accuracy: 0.4049 - val_loss: 1.3819 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.4250 - accuracy: 0.4102\n",
            "Epoch 10: val_accuracy did not improve from 0.44271\n",
            "24/24 [==============================] - 3s 126ms/step - loss: 1.4250 - accuracy: 0.4102 - val_loss: 1.4367 - val_accuracy: 0.4271 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.3826 - accuracy: 0.4297\n",
            "Epoch 11: val_accuracy improved from 0.44271 to 0.44792, saving model to best_model.h5\n",
            "24/24 [==============================] - 4s 180ms/step - loss: 1.3826 - accuracy: 0.4297 - val_loss: 1.4196 - val_accuracy: 0.4479 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.4104 - accuracy: 0.4193\n",
            "Epoch 12: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 3s 140ms/step - loss: 1.4104 - accuracy: 0.4193 - val_loss: 1.5112 - val_accuracy: 0.4271 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.3430 - accuracy: 0.4401\n",
            "Epoch 13: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 3s 143ms/step - loss: 1.3430 - accuracy: 0.4401 - val_loss: 1.5056 - val_accuracy: 0.4323 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.3820 - accuracy: 0.4310\n",
            "Epoch 14: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 3s 126ms/step - loss: 1.3820 - accuracy: 0.4310 - val_loss: 1.3440 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.3898 - accuracy: 0.4505\n",
            "Epoch 15: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 3s 145ms/step - loss: 1.3898 - accuracy: 0.4505 - val_loss: 1.4019 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.3480 - accuracy: 0.4388\n",
            "Epoch 16: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 4s 160ms/step - loss: 1.3480 - accuracy: 0.4388 - val_loss: 1.5399 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.3434 - accuracy: 0.4453\n",
            "Epoch 17: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 3s 125ms/step - loss: 1.3434 - accuracy: 0.4453 - val_loss: 1.4892 - val_accuracy: 0.4271 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2842 - accuracy: 0.4766\n",
            "Epoch 18: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 3s 121ms/step - loss: 1.2842 - accuracy: 0.4766 - val_loss: 1.3670 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.3142 - accuracy: 0.4648\n",
            "Epoch 19: val_accuracy did not improve from 0.44792\n",
            "24/24 [==============================] - 3s 122ms/step - loss: 1.3142 - accuracy: 0.4648 - val_loss: 1.4030 - val_accuracy: 0.4323 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2547 - accuracy: 0.4792\n",
            "Epoch 20: val_accuracy improved from 0.44792 to 0.46354, saving model to best_model.h5\n",
            "24/24 [==============================] - 4s 166ms/step - loss: 1.2547 - accuracy: 0.4792 - val_loss: 1.3754 - val_accuracy: 0.4635 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2565 - accuracy: 0.4883\n",
            "Epoch 21: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 130ms/step - loss: 1.2565 - accuracy: 0.4883 - val_loss: 1.6121 - val_accuracy: 0.2448 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2552 - accuracy: 0.4844\n",
            "Epoch 22: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 121ms/step - loss: 1.2552 - accuracy: 0.4844 - val_loss: 1.3467 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2918 - accuracy: 0.4727\n",
            "Epoch 23: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 141ms/step - loss: 1.2918 - accuracy: 0.4727 - val_loss: 1.3040 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2855 - accuracy: 0.4740\n",
            "Epoch 24: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 126ms/step - loss: 1.2855 - accuracy: 0.4740 - val_loss: 1.4833 - val_accuracy: 0.4323 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2038 - accuracy: 0.5117\n",
            "Epoch 25: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 137ms/step - loss: 1.2038 - accuracy: 0.5117 - val_loss: 1.3243 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2714 - accuracy: 0.4740\n",
            "Epoch 26: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 123ms/step - loss: 1.2714 - accuracy: 0.4740 - val_loss: 1.3299 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2180 - accuracy: 0.4935\n",
            "Epoch 27: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 124ms/step - loss: 1.2180 - accuracy: 0.4935 - val_loss: 1.3317 - val_accuracy: 0.4479 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2492 - accuracy: 0.5000\n",
            "Epoch 28: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 123ms/step - loss: 1.2492 - accuracy: 0.5000 - val_loss: 1.4135 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2367 - accuracy: 0.5013\n",
            "Epoch 29: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 139ms/step - loss: 1.2367 - accuracy: 0.5013 - val_loss: 1.3984 - val_accuracy: 0.4479 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1934 - accuracy: 0.5260\n",
            "Epoch 30: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 124ms/step - loss: 1.1934 - accuracy: 0.5260 - val_loss: 1.4960 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2360 - accuracy: 0.4883\n",
            "Epoch 31: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 125ms/step - loss: 1.2360 - accuracy: 0.4883 - val_loss: 1.5813 - val_accuracy: 0.4323 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2248 - accuracy: 0.5052\n",
            "Epoch 32: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 124ms/step - loss: 1.2248 - accuracy: 0.5052 - val_loss: 1.4084 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2078 - accuracy: 0.5013\n",
            "Epoch 33: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 127ms/step - loss: 1.2078 - accuracy: 0.5013 - val_loss: 1.4527 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2102 - accuracy: 0.5299\n",
            "Epoch 34: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 137ms/step - loss: 1.2102 - accuracy: 0.5299 - val_loss: 1.3700 - val_accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2148 - accuracy: 0.5156\n",
            "Epoch 35: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 120ms/step - loss: 1.2148 - accuracy: 0.5156 - val_loss: 1.8557 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2148 - accuracy: 0.4857\n",
            "Epoch 36: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 120ms/step - loss: 1.2148 - accuracy: 0.4857 - val_loss: 1.7564 - val_accuracy: 0.4323 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2033 - accuracy: 0.5000\n",
            "Epoch 37: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 119ms/step - loss: 1.2033 - accuracy: 0.5000 - val_loss: 1.5098 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2024 - accuracy: 0.5195\n",
            "Epoch 38: val_accuracy did not improve from 0.46354\n",
            "24/24 [==============================] - 3s 134ms/step - loss: 1.2024 - accuracy: 0.5195 - val_loss: 1.5335 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1853 - accuracy: 0.5130\n",
            "Epoch 39: val_accuracy improved from 0.46354 to 0.46875, saving model to best_model.h5\n",
            "24/24 [==============================] - 5s 216ms/step - loss: 1.1853 - accuracy: 0.5130 - val_loss: 1.2995 - val_accuracy: 0.4688 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1896 - accuracy: 0.5260\n",
            "Epoch 40: val_accuracy improved from 0.46875 to 0.47917, saving model to best_model.h5\n",
            "24/24 [==============================] - 4s 152ms/step - loss: 1.1896 - accuracy: 0.5260 - val_loss: 1.3184 - val_accuracy: 0.4792 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1395 - accuracy: 0.5443\n",
            "Epoch 41: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 126ms/step - loss: 1.1395 - accuracy: 0.5443 - val_loss: 1.3435 - val_accuracy: 0.4479 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1936 - accuracy: 0.5000\n",
            "Epoch 42: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 143ms/step - loss: 1.1936 - accuracy: 0.5000 - val_loss: 1.2852 - val_accuracy: 0.4688 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2034 - accuracy: 0.5117\n",
            "Epoch 43: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 121ms/step - loss: 1.2034 - accuracy: 0.5117 - val_loss: 1.4031 - val_accuracy: 0.4427 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1473 - accuracy: 0.5443\n",
            "Epoch 44: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 124ms/step - loss: 1.1473 - accuracy: 0.5443 - val_loss: 1.4428 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1899 - accuracy: 0.5039\n",
            "Epoch 45: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 121ms/step - loss: 1.1899 - accuracy: 0.5039 - val_loss: 1.3714 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1623 - accuracy: 0.5365\n",
            "Epoch 46: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 133ms/step - loss: 1.1623 - accuracy: 0.5365 - val_loss: 1.3837 - val_accuracy: 0.4740 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1370 - accuracy: 0.5339\n",
            "Epoch 47: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 127ms/step - loss: 1.1370 - accuracy: 0.5339 - val_loss: 1.3874 - val_accuracy: 0.4688 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.1933 - accuracy: 0.4974\n",
            "Epoch 48: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 124ms/step - loss: 1.1933 - accuracy: 0.4974 - val_loss: 1.3109 - val_accuracy: 0.4271 - lr: 1.0000e-04\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.0853 - accuracy: 0.5573\n",
            "Epoch 49: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 122ms/step - loss: 1.0853 - accuracy: 0.5573 - val_loss: 1.3213 - val_accuracy: 0.4531 - lr: 1.0000e-04\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.0889 - accuracy: 0.5664\n",
            "Epoch 50: val_accuracy did not improve from 0.47917\n",
            "24/24 [==============================] - 3s 126ms/step - loss: 1.0889 - accuracy: 0.5664 - val_loss: 1.5838 - val_accuracy: 0.4792 - lr: 1.0000e-04\n",
            "Done !!\n"
          ]
        }
      ],
      "source": [
        "from keras.engine.training import callbacks_module\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head..\")\n",
        "# print(train_generator.shape, test_generator.shape)\n",
        "\n",
        "# x_train = train_generator\n",
        "# y_train = train_generator.classes\n",
        "# print (len(y_train))\n",
        "\n",
        "h = cnn_model.fit(x_train, y_train, epochs=EPOCHS, validation_split=0.2, callbacks=my_callbacks)#validation_data=valid_generator, callbacks=my_callbacks)\n",
        "\n",
        "# h = cnn_model.fit(\n",
        "#         train_generator,\n",
        "#         # steps_per_epoch=len(train_generator) // BS,\n",
        "#         epochs=EPOCHS,\n",
        "#         validation_data=valid_generator,\n",
        "#         # validation_steps=len(valid_generator) // BS)\n",
        "#         callbacks = my_callbacks\n",
        "#         )\n",
        "print(\"Done !!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odrWjuB-hKRF",
        "outputId": "e2077c44-f45b-4541-c8dd-abe1b42483ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (6,6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    cm = np.round(cm,2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Nky3aNEqELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "XoFY_Xm6g-KO",
        "outputId": "a650e702-7822-454f-8c4b-231d0387a923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "8/8 [==============================] - 1s 93ms/step\n",
            "53/53 [==============================] - 17s 315ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-d2fe79e8f26e>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrainpredIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrainCNNScore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mCNNScore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [838, 960]"
          ]
        }
      ],
      "source": [
        "#!pip install scikit-plot\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scikitplot as skplt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import tensorflow\n",
        "\n",
        "cnn_model = tensorflow.keras.models.load_model('best_model.h5')\n",
        "# x_test = test_generator\n",
        "# x_train = train_generator\n",
        "# y_test = test_generator.classes\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = cnn_model.predict(x_test, batch_size=BS)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "trainpredIdxs = cnn_model.predict(x_train, batch_size=BS)\n",
        "trainpredIdxs = np.argmax(trainpredIdxs, axis=1)\n",
        "\n",
        "trainCNNScore=accuracy_score(trainpredIdxs,y_train.argmax(axis=1))*100\n",
        "CNNScore=accuracy_score(predIdxs,y_test.argmax(axis=1))*100\n",
        "\n",
        "print(\"\\nTrainig Accuracy Score:-\",trainCNNScore)\n",
        "print(\"\\nTesting Accuracy Score:-\",CNNScore)\n",
        "print(\"\\nTraning Graph:- \\n \")\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), h.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss vs. validation Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\",)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), h.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), h.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Accuracy vs. Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\",)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YDvUMUphWyY",
        "outputId": "510efeb2-316b-41de-ead9-7c03d612e806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 7s 244ms/step\n",
            "4/4 [==============================] - 1s 134ms/step\n",
            "(838, 1024)\n"
          ]
        }
      ],
      "source": [
        "extractCNN = Model(cnn_model.inputs, cnn_model.layers[-2].output)\n",
        "\n",
        "#del(data)\n",
        "#del(labels)\n",
        "feat_trainCNN  = extractCNN.predict(x_train)\n",
        "feat_testCNN = extractCNN.predict(x_test)\n",
        "\n",
        "print(feat_trainCNN.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwNaYsLKhjPJ",
        "outputId": "34e242f3-458b-404d-f85f-1ab3b5ab70d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Training Accuracy Score:- 0.45584725536992843\n",
            "\n",
            "SVM Testing Accuracy Score:- 0.4435483870967742\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "svm.fit(feat_trainCNN, y_train)#np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainSVMScoreCNN=svm.score(feat_trainCNN, y_train)#np.argmax(y_train,axis=1))*100\n",
        "print(\"SVM Training Accuracy Score:-\",TrainSVMScoreCNN)\n",
        "\n",
        "TestSVMScoreCNN=svm.score(feat_testCNN, y_test)#np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nSVM Testing Accuracy Score:-\",TestSVMScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "2MIzKIZfhqqC",
        "outputId": "013ca733-6b5d-496a-a5e9-7d655a2e0e6b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4e477d263fc6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_trainCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mTrainDecisionScoreCNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_trainCNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \"\"\"\n\u001b[1;32m   1215\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf = clf.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainDecisionScoreCNN=clf.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"Decision Tree Training Accuracy Score:-\",TrainDecisionScoreCNN)\n",
        "\n",
        "\n",
        "TestDecisionScoreCNN=clf.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nDecision Tree Testing Accuracy Score:-\",TestDecisionScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBnKNWgChyWV",
        "outputId": "2aaa1e44-1167-41f9-86a4-6d36edd9fed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Training Accuracy Score:- 88.20101966496723\n",
            "\n",
            "KNN Testing Accuracy Score:- 72.37991266375546\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainKNNScoreCNN=knn.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"KNN Training Accuracy Score:-\",TrainKNNScoreCNN)\n",
        "\n",
        "TestKNNScoreCNN=knn.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nKNN Testing Accuracy Score:-\",TestKNNScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gux9LyNoh5f7",
        "outputId": "dcc2bc1d-0e8f-466d-e85b-6772d3ec2541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GaussianNaive Bayes Training Accuracy Score:- 29.24253459577567\n",
            "\n",
            "GaussianNaive Bayes Testing Accuracy Score:- 27.074235807860266\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainNBScoreCNN=gnb.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Training Accuracy Score:-\",TrainNBScoreCNN)\n",
        "\n",
        "TestNBScoreCNN=gnb.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Testing Accuracy Score:-\",TestNBScoreCNN)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}