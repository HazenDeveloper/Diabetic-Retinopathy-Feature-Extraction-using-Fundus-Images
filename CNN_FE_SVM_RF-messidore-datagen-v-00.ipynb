{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazenDeveloper/Diabetic-Retinopathy-Feature-Extraction-using-Fundus-Images/blob/master/CNN_FE_SVM_RF-messidore-datagen-v-00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "VtDaOD9ibRNL",
        "outputId": "d133a24b-a6b4-4c86-9f14-0a52f3fa87ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ee6f9da-222c-4463-ba0f-7e19573f514b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ee6f9da-222c-4463-ba0f-7e19573f514b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkwlxHQGbW6e",
        "outputId": "28cd00dd-c9c6-44e6-e1f8-13d45a37e343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting q\n",
            "  Downloading q-2.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Installing collected packages: q\n",
            "Successfully installed q-2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZjrXEiisDLY"
      },
      "outputs": [],
      "source": [
        "!mkdir dir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPFA1Pe0bmg2",
        "outputId": "d9a15769-cc23-49b2-bc59-ff851abc8041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "401 - Unauthorized\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byg7fdPRb54g",
        "outputId": "6ccc6a71-8bb9-4d4e-9cb8-878dd554d1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading diabetic-retinopathy-224x224-gaussian-filtered.zip to /content\n",
            "100% 427M/427M [00:04<00:00, 108MB/s]\n",
            "100% 427M/427M [00:04<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "import kaggle\n",
        "!kaggle datasets download -d sovitrath/diabetic-retinopathy-224x224-gaussian-filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvnlrYLrcDlr"
      },
      "outputs": [],
      "source": [
        "!unzip diabetic-retinopathy-224x224-gaussian-filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAeA0Vt9cMDa",
        "outputId": "d27f9259-f5e3-45c4-a935-ec044296f43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Source code downloaded to /content/cnn-ml-classifier.ipynb\n"
          ]
        }
      ],
      "source": [
        "!kaggle kernels pull mahipalsingh/cnn-ml-classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcLeVn8mcX2A",
        "outputId": "14946750-84fc-416c-d1d8-f844fd30ec9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diabetic-retinopathy-224x224-gaussian-filtered.zip  kaggle.json\n",
            "dir\t\t\t\t\t\t    sample_data\n",
            "gaussian_filtered_images\t\t\t    train.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUzMl-LWi0Pl",
        "outputId": "53e895cd-17a0-4e9e-b8ff-1531287d324d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd '/content/drive'"
      ],
      "metadata": {
        "id": "FkQQaQb14Po7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive')"
      ],
      "metadata": {
        "id": "AOZoZEGI4bo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "hO8i_IgY6Hf3",
        "outputId": "caf7d124-cadc-43df-fae4-bf3932a8b5df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bFbjIBEyceKU"
      },
      "outputs": [],
      "source": [
        "#!pip install imutils\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from sklearn.utils import shuffle\n",
        "from cv2 import imread\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6laC8WbgD2O",
        "outputId": "0435a281-eb45-4239-be1d-3fe9728ea2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlL9rO5_5Si9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4fuzmF_0Yvr",
        "outputId": "36411b5b-90de-450d-8e49-31b2d025fea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML-Datasets/Messidore\n"
          ]
        }
      ],
      "source": [
        "from os import listdir, walk\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "path = os.path.join(os.path.curdir,'/content/drive/MyDrive/ML-Datasets/Messidore')\n",
        "print(path)\n",
        "\n",
        "# print('testing', imagePaths[1].split(os.path.sep)[-2])\n",
        "\n",
        "# img = cv2.imread(imagePaths[2])\n",
        "# cv2_imshow(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3NJxQMYNe0cC"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 4\n",
        "\n",
        "imagePaths = list(paths.list_images('/content/drive/MyDrive/ML-Datasets/Messidore'))\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/ML-Datasets/train-test-val-nc/train'\n",
        "test_data_dir = '/content/drive/MyDrive/ML-Datasets/train-test-val-nc/test'\n",
        "valid_data_dir = '/content/drive/MyDrive/ML-Datasets/train-test-val-nc/val'\n",
        "\n",
        "# data = []\n",
        "# labels = []\n",
        "\n",
        "# for imagePath in imagePaths:\n",
        "#     label = imagePath.split(os.path.sep)[-2]\n",
        "#     image = load_img(imagePath, target_size=(width, height))\n",
        "#     image = img_to_array(image)\n",
        "#     data.append(image)\n",
        "#     labels.append(label)\n",
        "\n",
        "# data = np.array(data, dtype=\"float32\")\n",
        "# labels = np.array(labels)\n",
        "# print(len(data), len(labels))\n",
        "\n",
        "# from sklearn.preprocessing import  LabelEncoder\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# # le = LabelEncoder()\n",
        "# # labels = le.fit_transform(labels)\n",
        "\n",
        "# # ohe = OneHotEncoder()\n",
        "# # labels = ohe.fit_transform(labels)\n",
        "\n",
        "# lb = LabelBinarizer()\n",
        "# labels = lb.fit_transform(labels)\n",
        "\n",
        "# #labels = to_categorical(labels)\n",
        "\n",
        "# data, labels = shuffle(data, labels)\n",
        "\n",
        "# print(data.shape)\n",
        "# print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtJkMb8RgeP3",
        "outputId": "c4e3dca3-fabc-442a-ae1c-b324d2111727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: (960, 256, 256, 3)\n",
            "Test images: (240, 256, 256, 3)\n",
            "Train label: (960, 4)\n",
            "Test label: (240, 4)\n"
          ]
        }
      ],
      "source": [
        "test_ratio = 0.2\n",
        "# train is now 75% of the entire data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio)\n",
        "\n",
        "print(\"Train images:\",x_train.shape)\n",
        "print(\"Test images:\",x_test.shape)\n",
        "print(\"Train label:\",y_train.shape)\n",
        "print(\"Test label:\",y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h3AGbb6ANCA",
        "outputId": "675861c8-2b66-4b17-b68c-1ebd35e3a06b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2929, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL3-vfwbNaNY",
        "outputId": "fffb1c58-6459-43e1-a229-ace59f01ff13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.3.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (3.3.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.7.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (0.41.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->lazypredict) (1.16.0)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLE4RO53NyW0"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=False, custom_metric=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "\n",
        "# Preprocess the training data with data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,            # Normalize pixel values to [0, 1]\n",
        "                                  #  rotation_range=15,         # Randomly rotate images by 10 degrees\n",
        "                                  #  width_shift_range=0.1,   # Randomly shift images horizontally by 10% of the width\n",
        "                                   # height_shift_range=0.1,  # Randomly shift images vertically by 10% of the height\n",
        "                                   # shear_range=0.1,         # Apply shear transformation with a shear angle of 10 degrees\n",
        "                                  #  zoom_range=0.2,          # Apply random zoom between 0.9x and 1.1x\n",
        "                                  #  horizontal_flip=True,    # Randomly flip images horizontally\n",
        "                                  #  vertical_flip=False      # Do not flip images vertically\n",
        "                                   )\n",
        "\n",
        "# Preprocess the validation and testing data (only rescale pixel values)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# Load and augment the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'   # Use categorical mode for multi-class classification\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the testing data\n",
        "test_generator = valid_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=BS,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "VzEdrvd5ynTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e08fc3-01ad-4458-9602-fad90b6e74d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 838 images belonging to 4 classes.\n",
            "Found 238 images belonging to 4 classes.\n",
            "Found 124 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MiniVGGNet(width, heigth, depth, classes):\n",
        "\tmodel = Sequential()\n",
        "\tinput_shape = (heigth, width, depth)\n",
        "\tchanDim = -1\n",
        "\n",
        "\tif keras.backend.image_data_format() == \"channel_first\":\n",
        "\t\tinput_shape = (depth, heigth, width)\n",
        "\t\tchanDim = 1\n",
        "\n",
        "\tmodel.add(Conv2D(16,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\t# model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(Conv2D(32,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(64,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(128,(3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t# model.add(BatchNormalization())\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(512, activation=\"relu\"))\n",
        "\t# model.add(BatchNormalization())\n",
        "\t# model.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(classes, activation=\"softmax\"))\n",
        "\n",
        "\treturn model\n"
      ],
      "metadata": {
        "id": "0YVgmPybsCro"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width,height=256,256\n",
        "depth = 3\n",
        "input_shape = (height, width, depth)\n",
        "\n",
        "classes = 4\n",
        "depth = 3\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS = 50\n",
        "\n",
        "from keras.optimizers import Nadam\n",
        "\n",
        "cnn_model = MiniVGGNet(width, height, depth, classes)\n",
        "\n",
        "opt = Nadam(learning_rate=INIT_LR)\n",
        "# opt = Adam(learning_rate=INIT_LR)\n",
        "# opt = gradient_descent_legacy.SGD (learning_rate = INIT_LR)\n",
        "cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "5y1WoLKLtt3p",
        "outputId": "0551650b-e1ee-41db-b577-39cfa851dd1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 256, 256, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 128, 128, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128, 128, 16)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 64, 64, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               16777728  \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,877,220\n",
            "Trainable params: 16,877,220\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path where you want to save the best model\n",
        "checkpoint_path = 'best_model.h5'\n",
        "\n",
        "# Create the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    patience = 2,\n",
        "    monitor='val_accuracy',       # Metric to monitor (could also be 'val_accuracy', etc.)\n",
        "    save_best_only=True,      # Saves only the best model based on the monitored metric\n",
        "    # save_weights_only=False,  # Set to True to save only the model's weights, not the whole model\n",
        "    verbose=1                 # Verbosity level: 0 - silent, 1 - progress bar, 2 - one line per epoch.\n",
        ")\n",
        "# checkpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, mode='auto')\n",
        "my_callbacks = [model_checkpoint]"
      ],
      "metadata": {
        "id": "oDaSr1KbyVcx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk-YNu0kgpnZ",
        "outputId": "55a477b7-f9de-4d0e-b443-b4f1ff7addce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training head..\n",
            "838\n",
            "Epoch 1/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 2.0662 - accuracy: 0.4284\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45798, saving model to best_model.h5\n",
            "27/27 [==============================] - 9s 326ms/step - loss: 2.0662 - accuracy: 0.4284 - val_loss: 1.3668 - val_accuracy: 0.4580\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2971 - accuracy: 0.4558\n",
            "Epoch 2: val_accuracy did not improve from 0.45798\n",
            "27/27 [==============================] - 6s 219ms/step - loss: 1.2971 - accuracy: 0.4558 - val_loss: 1.3513 - val_accuracy: 0.4580\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.3117 - accuracy: 0.4558\n",
            "Epoch 3: val_accuracy improved from 0.45798 to 0.46218, saving model to best_model.h5\n",
            "27/27 [==============================] - 8s 279ms/step - loss: 1.3117 - accuracy: 0.4558 - val_loss: 1.3493 - val_accuracy: 0.4622\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2740 - accuracy: 0.4618\n",
            "Epoch 4: val_accuracy did not improve from 0.46218\n",
            "27/27 [==============================] - 8s 284ms/step - loss: 1.2740 - accuracy: 0.4618 - val_loss: 1.3154 - val_accuracy: 0.4454\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2528 - accuracy: 0.4678\n",
            "Epoch 5: val_accuracy did not improve from 0.46218\n",
            "27/27 [==============================] - 6s 222ms/step - loss: 1.2528 - accuracy: 0.4678 - val_loss: 1.3309 - val_accuracy: 0.4244\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2497 - accuracy: 0.4690\n",
            "Epoch 6: val_accuracy did not improve from 0.46218\n",
            "27/27 [==============================] - 6s 233ms/step - loss: 1.2497 - accuracy: 0.4690 - val_loss: 1.2769 - val_accuracy: 0.4412\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2362 - accuracy: 0.4761\n",
            "Epoch 7: val_accuracy did not improve from 0.46218\n",
            "27/27 [==============================] - 8s 292ms/step - loss: 1.2362 - accuracy: 0.4761 - val_loss: 1.2704 - val_accuracy: 0.4580\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2210 - accuracy: 0.4940\n",
            "Epoch 8: val_accuracy did not improve from 0.46218\n",
            "27/27 [==============================] - 6s 220ms/step - loss: 1.2210 - accuracy: 0.4940 - val_loss: 1.2873 - val_accuracy: 0.4370\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2045 - accuracy: 0.5048\n",
            "Epoch 9: val_accuracy did not improve from 0.46218\n",
            "27/27 [==============================] - 8s 294ms/step - loss: 1.2045 - accuracy: 0.5048 - val_loss: 1.2744 - val_accuracy: 0.4580\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.2132 - accuracy: 0.4964\n",
            "Epoch 10: val_accuracy improved from 0.46218 to 0.46639, saving model to best_model.h5\n",
            "27/27 [==============================] - 6s 237ms/step - loss: 1.2132 - accuracy: 0.4964 - val_loss: 1.2595 - val_accuracy: 0.4664\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1968 - accuracy: 0.5095\n",
            "Epoch 11: val_accuracy did not improve from 0.46639\n",
            "27/27 [==============================] - 7s 266ms/step - loss: 1.1968 - accuracy: 0.5095 - val_loss: 1.2623 - val_accuracy: 0.4664\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1727 - accuracy: 0.5012\n",
            "Epoch 12: val_accuracy improved from 0.46639 to 0.47059, saving model to best_model.h5\n",
            "27/27 [==============================] - 7s 242ms/step - loss: 1.1727 - accuracy: 0.5012 - val_loss: 1.2574 - val_accuracy: 0.4706\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1756 - accuracy: 0.5227\n",
            "Epoch 13: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 246ms/step - loss: 1.1756 - accuracy: 0.5227 - val_loss: 1.2822 - val_accuracy: 0.4622\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1537 - accuracy: 0.5143\n",
            "Epoch 14: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 231ms/step - loss: 1.1537 - accuracy: 0.5143 - val_loss: 1.2577 - val_accuracy: 0.4454\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1411 - accuracy: 0.5286\n",
            "Epoch 15: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 263ms/step - loss: 1.1411 - accuracy: 0.5286 - val_loss: 1.2565 - val_accuracy: 0.4412\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1837 - accuracy: 0.5155\n",
            "Epoch 16: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 242ms/step - loss: 1.1837 - accuracy: 0.5155 - val_loss: 1.2549 - val_accuracy: 0.4412\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1443 - accuracy: 0.5263\n",
            "Epoch 17: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 217ms/step - loss: 1.1443 - accuracy: 0.5263 - val_loss: 1.2631 - val_accuracy: 0.4538\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1080 - accuracy: 0.5310\n",
            "Epoch 18: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 255ms/step - loss: 1.1080 - accuracy: 0.5310 - val_loss: 1.2883 - val_accuracy: 0.4580\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.1195 - accuracy: 0.5215\n",
            "Epoch 19: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 8s 289ms/step - loss: 1.1195 - accuracy: 0.5215 - val_loss: 1.3148 - val_accuracy: 0.4454\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.0789 - accuracy: 0.5609\n",
            "Epoch 20: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 224ms/step - loss: 1.0789 - accuracy: 0.5609 - val_loss: 1.3332 - val_accuracy: 0.4160\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.0672 - accuracy: 0.5609\n",
            "Epoch 21: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 8s 298ms/step - loss: 1.0672 - accuracy: 0.5609 - val_loss: 1.3112 - val_accuracy: 0.4538\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.0500 - accuracy: 0.5597\n",
            "Epoch 22: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 234ms/step - loss: 1.0500 - accuracy: 0.5597 - val_loss: 1.3069 - val_accuracy: 0.4496\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.0368 - accuracy: 0.5800\n",
            "Epoch 23: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 259ms/step - loss: 1.0368 - accuracy: 0.5800 - val_loss: 1.3730 - val_accuracy: 0.2857\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.9971 - accuracy: 0.5967\n",
            "Epoch 24: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 8s 289ms/step - loss: 0.9971 - accuracy: 0.5967 - val_loss: 1.3409 - val_accuracy: 0.3866\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 1.0008 - accuracy: 0.5883\n",
            "Epoch 25: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 223ms/step - loss: 1.0008 - accuracy: 0.5883 - val_loss: 1.3394 - val_accuracy: 0.3950\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.9756 - accuracy: 0.6074\n",
            "Epoch 26: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 242ms/step - loss: 0.9756 - accuracy: 0.6074 - val_loss: 1.3274 - val_accuracy: 0.4664\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.9553 - accuracy: 0.6014\n",
            "Epoch 27: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 8s 292ms/step - loss: 0.9553 - accuracy: 0.6014 - val_loss: 1.4009 - val_accuracy: 0.4076\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.9458 - accuracy: 0.6014\n",
            "Epoch 28: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 220ms/step - loss: 0.9458 - accuracy: 0.6014 - val_loss: 1.3666 - val_accuracy: 0.4244\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.8773 - accuracy: 0.6504\n",
            "Epoch 29: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 238ms/step - loss: 0.8773 - accuracy: 0.6504 - val_loss: 1.4312 - val_accuracy: 0.3992\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.8434 - accuracy: 0.6444\n",
            "Epoch 30: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 227ms/step - loss: 0.8434 - accuracy: 0.6444 - val_loss: 1.4461 - val_accuracy: 0.3824\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.8041 - accuracy: 0.6611\n",
            "Epoch 31: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 262ms/step - loss: 0.8041 - accuracy: 0.6611 - val_loss: 1.4728 - val_accuracy: 0.3950\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.6718\n",
            "Epoch 32: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 235ms/step - loss: 0.7781 - accuracy: 0.6718 - val_loss: 1.6107 - val_accuracy: 0.3361\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.7776 - accuracy: 0.6838\n",
            "Epoch 33: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 229ms/step - loss: 0.7776 - accuracy: 0.6838 - val_loss: 1.5956 - val_accuracy: 0.3445\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.7064\n",
            "Epoch 34: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 224ms/step - loss: 0.7131 - accuracy: 0.7064 - val_loss: 1.4998 - val_accuracy: 0.4034\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.7422\n",
            "Epoch 35: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 244ms/step - loss: 0.6928 - accuracy: 0.7422 - val_loss: 1.6105 - val_accuracy: 0.3697\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6892 - accuracy: 0.7196\n",
            "Epoch 36: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 276ms/step - loss: 0.6892 - accuracy: 0.7196 - val_loss: 1.6285 - val_accuracy: 0.3824\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.7411\n",
            "Epoch 37: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 225ms/step - loss: 0.6319 - accuracy: 0.7411 - val_loss: 1.5581 - val_accuracy: 0.3739\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5978 - accuracy: 0.7625\n",
            "Epoch 38: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 255ms/step - loss: 0.5978 - accuracy: 0.7625 - val_loss: 1.6569 - val_accuracy: 0.3992\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.7912\n",
            "Epoch 39: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 234ms/step - loss: 0.5123 - accuracy: 0.7912 - val_loss: 1.9799 - val_accuracy: 0.4370\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.7995\n",
            "Epoch 40: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 279ms/step - loss: 0.5221 - accuracy: 0.7995 - val_loss: 1.8816 - val_accuracy: 0.3950\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8055\n",
            "Epoch 41: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 225ms/step - loss: 0.5188 - accuracy: 0.8055 - val_loss: 1.7990 - val_accuracy: 0.3697\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.8329\n",
            "Epoch 42: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 268ms/step - loss: 0.4356 - accuracy: 0.8329 - val_loss: 2.0660 - val_accuracy: 0.3487\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.8353\n",
            "Epoch 43: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 226ms/step - loss: 0.4052 - accuracy: 0.8353 - val_loss: 1.9075 - val_accuracy: 0.3992\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.8508\n",
            "Epoch 44: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.3976 - accuracy: 0.8508 - val_loss: 2.1423 - val_accuracy: 0.4286\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8699\n",
            "Epoch 45: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 221ms/step - loss: 0.3530 - accuracy: 0.8699 - val_loss: 2.3591 - val_accuracy: 0.4454\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.8520\n",
            "Epoch 46: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 262ms/step - loss: 0.4142 - accuracy: 0.8520 - val_loss: 2.2462 - val_accuracy: 0.4496\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.9045\n",
            "Epoch 47: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 223ms/step - loss: 0.2702 - accuracy: 0.9045 - val_loss: 2.3702 - val_accuracy: 0.4412\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.9021\n",
            "Epoch 48: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 6s 228ms/step - loss: 0.2787 - accuracy: 0.9021 - val_loss: 2.4053 - val_accuracy: 0.4370\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8687\n",
            "Epoch 49: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 272ms/step - loss: 0.3843 - accuracy: 0.8687 - val_loss: 2.5321 - val_accuracy: 0.3950\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.8950\n",
            "Epoch 50: val_accuracy did not improve from 0.47059\n",
            "27/27 [==============================] - 7s 277ms/step - loss: 0.2652 - accuracy: 0.8950 - val_loss: 2.4957 - val_accuracy: 0.4286\n",
            "Done !!\n"
          ]
        }
      ],
      "source": [
        "from keras.engine.training import callbacks_module\n",
        "# train the head of the network\n",
        "print(\"[INFO] training head..\")\n",
        "# print(train_generator.shape, test_generator.shape)\n",
        "\n",
        "x_train = train_generator\n",
        "y_train = train_generator.classes\n",
        "print (len(y_train))\n",
        "\n",
        "h = cnn_model.fit(x_train,epochs=EPOCHS, validation_data=valid_generator, callbacks=my_callbacks)#validation_split=0.2, callbacks=my_callbacks)\n",
        "\n",
        "# h = cnn_model.fit(\n",
        "#         train_generator,\n",
        "#         # steps_per_epoch=len(train_generator) // BS,\n",
        "#         epochs=EPOCHS,\n",
        "#         validation_data=valid_generator,\n",
        "#         # validation_steps=len(valid_generator) // BS)\n",
        "#         callbacks = my_callbacks\n",
        "#         )\n",
        "print(\"Done !!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odrWjuB-hKRF",
        "outputId": "b2f901d3-bc83-4867-b7fc-cd5cb9f02bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "XoFY_Xm6g-KO",
        "outputId": "06e32a8d-7305-4ba3-9df5-3140ab5dd331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "4/4 [==============================] - 74s 25s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3c6462a0e5b4>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpredIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrainpredIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtrainpredIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainpredIdxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ],
      "source": [
        "#!pip install scikit-plot\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scikitplot as skplt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import tensorflow\n",
        "\n",
        "cnn_model = tensorflow.keras.models.load_model('best_model.h5')\n",
        "x_test = test_generator\n",
        "x_train = train_generator\n",
        "y_train=\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = cnn_model.predict(x_test, batch_size=BS)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "trainpredIdxs = cnn_model.predict(x_train, batch_size=BS)\n",
        "trainpredIdxs = np.argmax(trainpredIdxs, axis=1)\n",
        "\n",
        "trainCNNScore=accuracy_score(trainpredIdxs,y_train.argmax(axis=1))*100\n",
        "CNNScore=accuracy_score(predIdxs,y_test.argmax(axis=1))*100\n",
        "\n",
        "print(\"\\nTrainig Accuracy Score:-\",trainCNNScore)\n",
        "print(\"\\nTesting Accuracy Score:-\",CNNScore)\n",
        "print(\"\\nTraning Graph:- \\n \")\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), h.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss vs. validation Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\",)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), h.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), h.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Accuracy vs. Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\",)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YDvUMUphWyY",
        "outputId": "3d4e9c10-8023-42e5-b947-2035bcb3ce0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - 1s 5ms/step\n",
            "29/29 [==============================] - 0s 6ms/step\n",
            "(2746, 1024)\n"
          ]
        }
      ],
      "source": [
        "extractCNN = Model(cnn_model.inputs, cnn_model.layers[-4].output)\n",
        "\n",
        "#del(data)\n",
        "#del(labels)\n",
        "feat_trainCNN  = extractCNN.predict(x_train)\n",
        "feat_testCNN = extractCNN.predict(x_test)\n",
        "\n",
        "print(feat_trainCNN.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwNaYsLKhjPJ",
        "outputId": "52770add-6363-43d5-b0ec-5a0d677efa24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Training Accuracy Score:- 99.38091769847051\n",
            "\n",
            "SVM Testing Accuracy Score:- 72.16157205240175\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainSVMScoreCNN=svm.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"SVM Training Accuracy Score:-\",TrainSVMScoreCNN)\n",
        "\n",
        "TestSVMScoreCNN=svm.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nSVM Testing Accuracy Score:-\",TestSVMScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MIzKIZfhqqC",
        "outputId": "042d0aae-a719-437e-ddd6-0b156cc3410f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Training Accuracy Score:- 99.38091769847051\n",
            "\n",
            "Decision Tree Testing Accuracy Score:- 65.06550218340611\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf = clf.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainDecisionScoreCNN=clf.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"Decision Tree Training Accuracy Score:-\",TrainDecisionScoreCNN)\n",
        "\n",
        "\n",
        "TestDecisionScoreCNN=clf.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nDecision Tree Testing Accuracy Score:-\",TestDecisionScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBnKNWgChyWV",
        "outputId": "2aaa1e44-1167-41f9-86a4-6d36edd9fed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Training Accuracy Score:- 88.20101966496723\n",
            "\n",
            "KNN Testing Accuracy Score:- 72.37991266375546\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainKNNScoreCNN=knn.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"KNN Training Accuracy Score:-\",TrainKNNScoreCNN)\n",
        "\n",
        "TestKNNScoreCNN=knn.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nKNN Testing Accuracy Score:-\",TestKNNScoreCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gux9LyNoh5f7",
        "outputId": "dcc2bc1d-0e8f-466d-e85b-6772d3ec2541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GaussianNaive Bayes Training Accuracy Score:- 29.24253459577567\n",
            "\n",
            "GaussianNaive Bayes Testing Accuracy Score:- 27.074235807860266\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n",
        "\n",
        "TrainNBScoreCNN=gnb.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Training Accuracy Score:-\",TrainNBScoreCNN)\n",
        "\n",
        "TestNBScoreCNN=gnb.score(feat_testCNN,np.argmax(y_test,axis=1))*100\n",
        "print(\"\\nGaussianNaive Bayes Testing Accuracy Score:-\",TestNBScoreCNN)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}